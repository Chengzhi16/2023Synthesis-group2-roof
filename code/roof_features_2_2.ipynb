{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741f5ff7-c035-447b-91ab-2d44e16e591c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tkinter as tk\n",
    "from tkinter.simpledialog import askinteger\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "from tkinter import simpledialog\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "# from cjio import cityjson\n",
    "from shapely.geometry import Polygon,Point\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from sklearn import cluster\n",
    "import numpy as np\n",
    "import shapely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eabd70ad-bfbf-4e25-9527-100541cef62e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geojson_file = \"denhaag_roof.geojson\"\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "gdf['centroid'] = gdf.centroid\n",
    "\n",
    "# for column_name in gdf.columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b1460a-2d5d-4feb-8aa7-f1f64b9e0c0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = '''id,\n",
    "             intersection_angle_max_min,\n",
    "             largest_polygon_area,\n",
    "             second_largest_polygon_area,\n",
    "             second_largest_degree,\n",
    "             ground_degree_avg,\n",
    "             ground_degree_std,\n",
    "             ground_degree_median,\n",
    "             Min_Area_Proportion,\n",
    "             Absolute_Max_Height (roof to ground),\n",
    "             Relative_Max_Height (Maximum roof height - minimum), \n",
    "             \n",
    "             Roof_height_standard_deviation, \n",
    "             Roof_height_median, \n",
    "             The number of small roof parts,  \n",
    "             The area proportion of small roof parts,   \n",
    "             \n",
    "             the squareness_avg, \n",
    "             the squareness_med, \n",
    "             the squareness_std'''\n",
    "#the number of horizontal roofs, \n",
    "attributes = {attribute.strip():[] for attribute in attributes.split(\",\")}\n",
    "print(attributes)\n",
    "for geom in gdf.values:\n",
    "        ids,multi_polygon = geom[0],geom[-2]\n",
    "        print(\"id is :\",ids)\n",
    "        attributes[\"id\"].append(ids)\n",
    "        areas = {i: poly.area for i, poly in enumerate(multi_polygon)}\n",
    "        ground_normal = np.array([0, 0, 1])\n",
    "        \n",
    "\n",
    "        # calculate the normal vector of the polygon\n",
    "        def calculate_normal(coords):\n",
    "            p1, p2, p3 = coords[:3]\n",
    "            \n",
    "            v1 = np.array([p2[0] - p1[0], p2[1] - p1[1],p2[2] - p1[2]])\n",
    "            v2 = np.array([p3[0] - p1[0], p3[1] - p1[1],p2[2] - p1[2]])\n",
    "            normal = np.cross(v1, v2)\n",
    "            length = np.linalg.norm(normal)\n",
    "\n",
    "            # normalize the normal vector\n",
    "            normalized_vector = normal / length\n",
    "            return normalized_vector\n",
    "\n",
    "        \n",
    "        def calculate_degree(vector1,vector2):\n",
    "            angle_rad = np.arccos(np.dot(vector1, vector2))\n",
    "\n",
    "            # convert radians to degrees\n",
    "            angle_deg = abs(np.degrees(angle_rad))\n",
    "            if abs(angle_deg) <4:\n",
    "                angle_deg =0\n",
    "            elif abs(angle_deg-90) <4:\n",
    "                angle_deg = 90\n",
    "            elif abs(angle_deg-180) <4:\n",
    "                angle_deg = 0\n",
    "            elif abs(angle_deg-270) <4:\n",
    "                angle_deg = 90\n",
    "            elif abs(angle_deg-360) <4:\n",
    "                angle_deg = 0\n",
    "            return angle_deg\n",
    "        \n",
    "        def calculate_centroid(polygon):\n",
    "            vertices = list(polygon.exterior.coords)\n",
    "\n",
    "            # calculate the number of vertices\n",
    "            n = len(vertices)\n",
    "\n",
    "            # initialize coordinate sums\n",
    "            sum_x, sum_y, sum_z = 0, 0, 0\n",
    "\n",
    "            # calculate coordinate sums\n",
    "            for x, y, z in vertices:\n",
    "                sum_x += x\n",
    "                sum_y += y\n",
    "                sum_z += z\n",
    "\n",
    "            # calculate centroid using coordinate sums\n",
    "            centroid_x = sum_x / n\n",
    "            centroid_y = sum_y / n\n",
    "            centroid_z = sum_z / n\n",
    "            return Point(centroid_x,centroid_y,centroid_z)\n",
    "        \n",
    "        def calculate_squareness(polygon):\n",
    "            bounds = polygon.bounds\n",
    "            width = bounds[2] - bounds[0]\n",
    "            height = bounds[3] - bounds[1]\n",
    "\n",
    "            # Calculate the aspect ratio (squareness)\n",
    "            aspect_ratio = max(width, height) / min(width, height)\n",
    "\n",
    "            return aspect_ratio\n",
    "        \n",
    "        sorted_areas2 = sorted(areas.items(), key=lambda x: x[1], reverse=True)\n",
    "        sorted_areas = np.array([poly.area for i, poly in enumerate(multi_polygon)])\n",
    "        print(sorted_areas)\n",
    "        polygons = [multi_polygon[index] for index in range(len(multi_polygon))]\n",
    "        \n",
    "        squareness = np.array([calculate_squareness(poly) for poly in polygons])\n",
    "        attributes[\"the squareness_avg\"].append(squareness.mean()) \n",
    "        attributes[\"the squareness_std\"].append(squareness.std()) \n",
    "        attributes[\"the squareness_med\"].append(np.median(squareness))\n",
    "        \n",
    "        # calculate normal vectors for all polygons\n",
    "        coords = [list(polygon.exterior.coords) for polygon in multi_polygon]\n",
    "    \n",
    "        vectors = [calculate_normal(coord) for coord in coords]\n",
    "        vectors_ground = np.array([calculate_degree(vector,ground_normal) for vector in vectors ])\n",
    "        attributes[\"ground_degree_avg\"].append(vectors_ground.mean())\n",
    "        attributes[\"ground_degree_std\"].append(vectors_ground.std())\n",
    "        attributes[\"ground_degree_median\"].append(np.median(vectors_ground))\n",
    "        #attributes[\"the number of horizontal roofs\"].append(sum(vectors_ground==0))\n",
    "\n",
    "\n",
    "        attributes[\"Min_Area_Proportion\"].append(min(sorted_areas)/sum(sorted_areas))\n",
    "            \n",
    "        \n",
    "        height = np.array([calculate_centroid(poly).z for poly in polygons])\n",
    "        height_avg = height.mean()\n",
    "        height_std = height.std()\n",
    "        height_median = np.median(height)\n",
    "        attributes[\"Roof_height_median\"].append(height_median)\n",
    "        attributes[\"Roof_height_standard_deviation\"].append(height_std)\n",
    "        attributes[\"The number of small roof parts\"].append(sum(sorted_areas<5))\n",
    "    \n",
    "        \n",
    "        attributes[\"The area proportion of small roof parts\"].append(sum(sorted_areas[sorted_areas<5])/sum(sorted_areas))\n",
    "        attributes[\"Absolute_Max_Height (roof to ground)\"].append(max(height))\n",
    "        attributes[\"Relative_Max_Height (Maximum roof height - minimum)\"].append(max(height)-min(height))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(sorted_areas) == 1:\n",
    "            attributes[\"intersection_angle_max_min\"].append(0)\n",
    "            attributes[\"largest_polygon_area\"].append(areas[sorted_areas2[0][0]])\n",
    "            #print(\"max areas\",areas[sorted_polygons[0][0]])\n",
    "            attributes[\"second_largest_polygon_area\"].append(0)\n",
    "\n",
    "            attributes[\"second_largest_degree\"].append(0)\n",
    "        \n",
    "        else:\n",
    "            largest_polygon_index = sorted_areas2[0][0]\n",
    "            second_largest_polygon_index = sorted_areas2[1][0]\n",
    "\n",
    "            # get the largest and second largest polygon\n",
    "            largest_polygon = multi_polygon[largest_polygon_index]\n",
    "            second_largest_polygon = multi_polygon[second_largest_polygon_index]\n",
    "            attributes[\"largest_polygon_area\"].append(areas[sorted_areas2[0][0]])\n",
    "            attributes[\"second_largest_polygon_area\"].append(areas[sorted_areas2[1][0]])\n",
    "\n",
    "            # calculate the normal vector of the polygon\n",
    "            largest_coords = list(largest_polygon.exterior.coords)\n",
    "            second_largest_coords = list(second_largest_polygon.exterior.coords)\n",
    "            vector1 = calculate_normal(largest_coords)\n",
    "            vector2 = calculate_normal(second_largest_coords)\n",
    "            # calculate the intersection angle between the two polygons\n",
    "\n",
    "            attributes[\"intersection_angle_max_min\"].append(calculate_degree(vector1,vector2)) \n",
    "\n",
    "            attributes[\"second_largest_degree\"].append(calculate_degree(vector2,ground_normal)) \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d42f7c-b169-4ada-967a-544ee77d56e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(attributes)\n",
    "dataframe.head()\n",
    "\n",
    "# Assuming 'dataframe' is a DataFrame containing your data\n",
    "with open(\"denhaag_roof_new_a.csv\", \"w\", newline=\"\\n\") as file:\n",
    "    dataframe.to_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "973c5e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_14504\\1115074889.py:4: DtypeWarning: Columns (0,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_old = pd.read_csv(\"denhaag_roof_old.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# clean the first roof feature CSV file\n",
    "# Load the first roof feature CSV file into a DataFrame\n",
    "df_old = pd.read_csv(\"denhaag_roof_old.csv\")\n",
    "\n",
    "# Get a list of column names to drop\n",
    "columns_to_drop = [col for col in df_old.columns if col.startswith(\"Unnamed:\")]\n",
    "\n",
    "# Drop the specified columns\n",
    "df_old = df_old.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df_old.to_csv(\"denhaag_roof_old_cleaned.csv\")\n",
    "\n",
    "#print(df_old.head())\n",
    "#print(df_old.columns)\n",
    "#df_new = pd.read_csv(\"denhaag_roof_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1f2bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0_x', 'Unnamed: 0_y']\n"
     ]
    }
   ],
   "source": [
    "#merge two csv files\n",
    "import pandas as pd\n",
    "\n",
    "# Load the first roof feature and the second roof feature CSV files into DataFrames\n",
    "df_old = pd.read_csv(\"denhaag_roof_old_horzontial.csv\")\n",
    "\n",
    "df_new = pd.read_csv(\"denhaag_roof_new_a.csv\")\n",
    "\n",
    "# Merge the DataFrames based on the common columns \"id\" and \"ID\"\n",
    "merged_df = pd.merge(df_old, df_new, left_on=\"Id\", right_on=\"id\")\n",
    "\n",
    "# Drop one of the duplicate columns (e.g., \"Id\" or \"id\") if needed\n",
    "merged_df.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "columns_to_drop = [col for col in merged_df.columns if col.startswith(\"Unnamed:\")]\n",
    "print(columns_to_drop)\n",
    "# Drop the specified columns\n",
    "merged_df_clean = merged_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df_clean.to_csv(\"merged_denhaag_roof_features_a.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
